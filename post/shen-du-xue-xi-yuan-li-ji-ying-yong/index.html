<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" >

<title>深度学习原理及应用 | dyxcrystal</title>

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="shortcut icon" href="https://dyxcrystal.github.io/favicon.ico?v=1611888224063">
<link rel="stylesheet" href="https://dyxcrystal.github.io/styles/main.css">



<link rel="stylesheet" href="https://unpkg.com/aos@next/dist/aos.css" />
<script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>



    <meta name="description" content="摘要：
深度学习起源于人工神经网络，通过组合低层特征形成更加抽象的高层表示属性类别或特征，以发现数据的分布式特征表示。其中卷积神经网络在图像处理上效果显著，递归神经网络则在处理文本、语音等序列数据上表现出色。
关键词：深度学习 卷积神经网络..." />
    <meta name="keywords" content="专业知识" />
  </head>
  <body>
    <div id="app" class="main">

      <div class="sidebar" :class="{ 'full-height': menuVisible }">
  <div class="top-container" data-aos="fade-right">
    <div class="top-header-container">
      <a class="site-title-container" href="https://dyxcrystal.github.io">
        <img src="https://dyxcrystal.github.io/images/avatar.png?v=1611888224063" class="site-logo">
        <h1 class="site-title">dyxcrystal</h1>
      </a>
      <div class="menu-btn" @click="menuVisible = !menuVisible">
        <div class="line"></div>
      </div>
    </div>
    <div>
      
        
          <a href="/" class="site-nav">
            首页
          </a>
        
      
        
          <a href="/archives" class="site-nav">
            归档
          </a>
        
      
        
          <a href="/tags" class="site-nav">
            标签
          </a>
        
      
        
          <a href="/post/about" class="site-nav">
            关于
          </a>
        
      
    </div>
  </div>
  <div class="bottom-container" data-aos="flip-up" data-aos-offset="0">
    <div class="social-container">
      
        
      
        
      
        
      
        
      
        
      
    </div>
    <div class="site-description">
      一个小天地
    </div>
    <div class="site-footer">
      Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | <a class="rss" href="https://dyxcrystal.github.io/atom.xml" target="_blank">RSS</a>
    </div>
  </div>
</div>


      <div class="main-container">
        <div class="content-container" data-aos="fade-up">
          <div class="post-detail">
            <h2 class="post-title">深度学习原理及应用</h2>
            <div class="post-date">2021-01-29</div>
            
            <div class="post-content" v-pre>
              <p>摘要：</p>
<p>深度学习起源于人工神经网络，通过组合低层特征形成更加抽象的高层表示属性类别或特征，以发现数据的分布式特征表示。其中卷积神经网络在图像处理上效果显著，递归神经网络则在处理文本、语音等序列数据上表现出色。</p>
<p>关键词：深度学习 卷积神经网络 递归神经网络</p>
<p>Abstract:</p>
<p>Deep learning originated from artificial neural networks, which combines low-level features to form more abstract high-level representation attribute categories or features to discover distributed feature representations of data. Among them, the convolutional neural network is effective in image processing, and the recurrent neural network performs well in processing sequence data such as text and speech.</p>
<p>Key words: deep Learning ; convolutional neural network ; recurrent neural network</p>
<p>正文</p>
<p>何为“深度学习”</p>
<p>​    要学习深度学习，我们首先要了解这一名词的含义。深度学习与浅学习相似，都使用神经网络来学习数据中有效的特征表示。对“学习”一词，我理解为用计算机模拟人类的学习行为，通过学习已有数据获得处理未知数据的能力。“深度”指的是神经网络学习得到的函数中非线性运算组合水平的数量，与浅学习相比，深度学习隐层网络数量更多，能更好地学习大量数据中包含的特征，从而表达高阶复杂目标函数。深度学习的核心优势是，各层的特征都不是利用人工来设计的，而是使用一种通用的学习过程从数据中学到的，因此不再需要使用者具备大量的工程技术和专业领域知识。</p>
<p>​</p>
<p>深度学习基本原理</p>
<p>虽然深度学习比浅层神经网络具有更强的特征表示能力，但普通神经网络常用的BP算法不适用于具有多隐含层的深度神经网络的训练。BP算法是采用梯度下降并随机选定初始值的网络训练方法，但因为输入于输出之间的非线性映射使得网络误差函数是一个含有多个极小点的非线性空间，搜索方向又仅仅依靠网络误差减小确定，因此经常收敛到局部最小值，并随着隐层网络层数增加愈加严重。</p>
<p>2006年Hinton提出的用于深度信任网络（Deep Belief Network,DBN）的无监督学习算法有效地解决了上述问题。求解DBN方法的核心是贪婪逐层预训练算法，它整体上是一个分层训练机制，通过无监督学习实现逐层初始化，从而克服了深度神经网络在训练上的难度。在深度学习的逐层预训练算法中首先将无监督学习应用于网络每一层的预训练，每次只无监督训练一层，并将该层的训练结果作为其下一层的输入，然后再用BP算法微调训练好的网络，这种深度学习预训练方法在标注样本数量有限时能使识别效果得到显著提升。</p>
<p>深度学习典型模型及应用</p>
<p>卷积神经网络CNN</p>
<p>上一节提到，在无监督预训练出现之前，训练深度神经网络通常非常困难，而其中一个特例是卷积神经网络（Convolutional Neural Networks，CNN），它是一种深层前馈型神经网络，在计算机视觉领域取得了很好的应用效果。</p>
<p>1980年，Fukushima根据生物对视觉处理的原理提出了结构与之类似的神经认知机，神经认知机采用简单细胞层（S层）和复杂细胞层（C-layer，C 层）交替组成，尽管在神经认知机中没有像 BP 算法那样的全局监督学习过程可利用，但它仍可认为是 CNN 的第一个工程实现网络。</p>
<p>LeCun等人基于Fukushima的研究工作使用误差梯度回传方法设计并训练了CNN。CNN 的基本结构由输入层、卷积层、取样层（池化层）、全连接层及输出层构成。由于卷积层中输出特征面的每个神经元与其输入进行局部连接，并通过对应的连接权值与局部输入进行加权求和再加上偏置值，得到该神经元输入值，该过程等价于卷积过程，故得名为卷积神经网络。当时CNN虽然在小规模的问题上例如手写数字识别取得了很好的结果，但对大规模图像处理不好,并没有得到计算机视觉领域的重视。</p>
<p>2012年Hinton等人在著名的ImageNet问题上，通过加深 CNN 模型的深度并采用 ReLU+dropout技术，达到了防止过拟合的目的，取得了当时最好的分类结果（该网络结构也被称为AlexNet）。卷积神经网络现在常常被用来做自然图形中的物体识别，比如脸、手以及人脸识别。</p>
<p>​</p>
<p>递归神经网络RNN</p>
<p>​    当我们在理解一句话时，孤立地去理解这句话的每个词是不够的，我们需要处理这些词连接起来的整个序列；当我们处理视频的时候，也不能只单独的去分析每一帧，而要分析这些帧连接起来的整个序列，递归神经网络（Recurrent Neural Network，RNN）就常常用于处理这一类序列问题。</p>
<p>​    RNN具体表现为网络会记忆以前的知识来帮助当前任务的完成。像所有人工神经网络一样，RNN的单元为其多个输入分配一个权重矩阵，这些权重代表各个输入在网络层中所占的比重；然后对这些权重应用一个函数来确定单个输出。然而，循环神经网络不仅对当前输入分配权重，而且还从对过去时刻输入分配权重。然后，通过使得损失函数最下来动态的调整分配给当前输入和过去输入的权重。</p>
<p>RNN网络使用的训练方法为通过时间的反向传播（BPTT），该算法扩展了BP算法的调整过程，包括负责前一时刻（T-1）输入值对应的每个单元的记忆的权重。递归神经网络的训练需要使用BPTT计算参数的梯度，其本质仍然是梯度的链式传递法则，很难长期保存信息，存在严重的梯度消散现象，长短时记忆模型（LSTM）的出现解决了上述问题。LSTM采用一种称作记忆细胞的特殊单元类似累加器和门控神经元：它在下一个时间步长将拥有一个权值并联接到自身，拷贝自身状态的真实值和累积的外部信号，但这种自联接是由另一个单元学习并决定何时清除记忆内容的乘法门控制的。</p>
<p>​    目前，循环神经网络已经成为深度学习领域中一类非常重要的模型，该网络在处理文本、音频和视频等序列数据上取得了瞩目的成果。</p>
<p>结论</p>
<p>深度学习自2006年以来在语音、图像、自然语言等领域取得显著进展，可以说它带来了机器学习的一个新浪潮。目前深度学习的训练依赖对大量数据进行计算，且需要大量的人工调参工作，我想大量数据的采集质量是一个值得关注的问题。同时神经网络的计算能力受到CPU的限制， 我们小组完成一个人手识别的小项目电脑都需要跑将近半小时，未来深度学习如果能在速度和体量上取得进展，就可以在移动设备和其它场所中得到更广泛的应用。深度学习最终目标是模拟人的思维，但人并不像深度学习网络这样需要庞大的数据进行训练，感觉深度学习主要是基于数据做分析，在逻辑思考方面还有很大发展空间。总之，深度学习在近十年来应用上取得了很大进展，也仍有很多可以改进、探索的空间。</p>
<p>参考文献：</p>
<p>[1] Bengio Y . Learning Deep Architectures for AI[J]. Foundations &amp; Trends in Machine Learning, 2009, 2(1):1-127.</p>
<p>[2] Hinton G , Salakhutdinov R . Reducing the dimensionality of data with neural networks[J]. Science, 2006, 313(5786):p. 504-507.</p>
<p>[3] Lecun Y , Bengio Y , Hinton G . Deep learning[J]. Nature, 2015, 521(7553):436.</p>
<p>[4] [1]Hinton, G. E., Osindero, S. &amp; Teh, Y.-W. A fast learning algorithm for deep belief nets. Neural Comp. 18, 1527–1554 (2006).</p>
<p>[5]https://www.researchgate.net/publication/277603865_A_Critical_Review_of_Recurrent_Neural_Networks_for_Sequence_Learning</p>
<p>[6] 余凯, 贾磊, 陈雨强,等. 深度学习的昨天,今天和明天[C]// 2013年中国计算机学会人工智能会议. 0.</p>
<p>[7] 胡越, 罗东阳, 花奎, et al. 关于深度学习的综述与讨论[J]. 智能系统学报, 2019, 14(01):1-19.</p>
<p>[8] 刘建伟, 刘媛, 罗雄麟. 深度学习研究进展[J]. 计算机应用研究, 2014(07):1921-1930.</p>
<p>[9] 周飞燕, 金林鹏, 董军. 卷积神经网络研究综述[J]. 计算机学报, 2017(6).</p>
<p>[10] 杨丽, 吴雨茜, 王俊丽, et al. 循环神经网络研究综述[J]. 计算机应用, 2018, 38(S2):6-11+31.</p>

            </div>
            
              <div class="tag-container">
                
                  <a href="https://dyxcrystal.github.io/tag/uP9OV4bLT/" class="tag">
                    专业知识
                  </a>
                
              </div>
            
            
              <div class="next-post">
                <div class="next">下一篇</div>
                <a href="https://dyxcrystal.github.io/post/stm32-shi-yan-8-dian-ji-diao-su/">
                  <h3 class="post-title">
                    STM32实验8——电机调速
                  </h3>
                </a>
              </div>
            

            

          </div>

        </div>
      </div>
    </div>

    <script src="https://unpkg.com/aos@next/dist/aos.js"></script>
<script type="application/javascript">

AOS.init();

var app = new Vue({
  el: '#app',
  data: {
    menuVisible: false,
  },
})

</script>






  </body>
</html>
